{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objs as go\n",
    "import plotly.offline as pyo\n",
    "from dateutil import parser\n",
    "from Strategies import AmipyNF\n",
    "from kiteconnect import KiteConnect\n",
    "from Brokers import apikey\n",
    "\n",
    "import pandas as pd\n",
    "from kiteconnect import KiteConnect\n",
    "import undetected_chromedriver as uc\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from datetime import datetime\n",
    "import time, pyotp\n",
    "\n",
    "import logging\n",
    "from kiteconnect import KiteTicker\n",
    "from kiteconnect import KiteConnect\n",
    "from Brokers import apikey\n",
    "from datetime import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = [256265]\n",
    "acctkn_file = r'Brokers\\acc_token.txt'\n",
    "reqtkn_file = r'Brokers\\req_token.txt'\n",
    "kite_access_token = open(acctkn_file,'r').read()\n",
    "kite_request_token = open(reqtkn_file,'r').read()\n",
    "kite = KiteConnect(apikey.kite_api_key)\n",
    "kite.set_access_token(kite_access_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from_date = '2023-05-01'\n",
    "to_date = '2023-05-23'\n",
    "interval = 'minute'\n",
    "nf_hist_data = kite.historical_data(tokens[0], from_date, to_date, interval)\n",
    "# Convert historical_data to pandas dataframe\n",
    "nf_df = pd.DataFrame(nf_hist_data)\n",
    "nf_df = nf_df.set_index('date')\n",
    "nf_df.to_csv('nf_kite_3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nf_kite = pd.read_csv('nf_kite.csv')\n",
    "nf_kite_2 = pd.read_csv('nf_kite_2.csv')\n",
    "nf_kite_3 = pd.read_csv('nf_kite_3.csv')\n",
    "\n",
    "nf_kite = pd.concat([nf_kite, nf_kite_2, nf_kite_3])\n",
    "\n",
    "nf_kite = nf_kite.set_index('date')\n",
    "nf_kite.to_csv('nf_kite_consolidated.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "def concat_nifty_files(folder_path, output_csv):\n",
    "    # Column names\n",
    "    column_names = ['Ticker', 'Date', 'Time', 'Open', 'High', 'Low', 'Close', 'Vol', 'OI']\n",
    "    \n",
    "    # Initialize an empty list to hold dataframes\n",
    "    df_list = []\n",
    "\n",
    "    # Loop through the years you are interested in\n",
    "    for year in range(2019, 2024):  # replace 2024 with current year + 1\n",
    "        # Pattern to match NIFTY files\n",
    "        file_pattern = f'{folder_path}/{year}*NIFTY.txt'\n",
    "\n",
    "        # Get all the matching file names\n",
    "        nifty_files = glob.glob(file_pattern)\n",
    "    \n",
    "        # Loop through all the files and read them into dataframes\n",
    "        for file in nifty_files:\n",
    "            print(f\"Processing file: {file}\")\n",
    "            try:\n",
    "                df = pd.read_csv(file, header=None)\n",
    "                df.columns = column_names\n",
    "                df_list.append(df)\n",
    "            except Exception as e:\n",
    "                print(f\"Error encountered while processing file: {file}\")\n",
    "                print(f\"Error message: {str(e)}\")\n",
    "                continue\n",
    "\n",
    "    # Concatenate all the dataframes\n",
    "    combined_df = pd.concat(df_list, ignore_index=True)\n",
    "    \n",
    "    # Convert the 'Date' column to datetime\n",
    "    combined_df['Date'] = pd.to_datetime(combined_df['Date'], format='%Y%m%d')\n",
    "    \n",
    "    # Sort by date and time\n",
    "    combined_df = combined_df.sort_values(by=['Date', 'Time'])\n",
    "\n",
    "    # Write the dataframe to a csv file\n",
    "    combined_df.to_csv(output_csv, index=False)\n",
    "\n",
    "# Call the function\n",
    "folder_path = r\"C:\\Users\\user\\Downloads\\Intraday 1 Min Data\\Consolidated\"\n",
    "output_csv = 'nifty_data.csv'  # output csv file name\n",
    "concat_nifty_files(folder_path, output_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Load the data from the CSV files\n",
    "df1 = pd.read_csv('nifty_data.csv')\n",
    "df2 = pd.read_csv('nf_kite_consolidated.csv')\n",
    "\n",
    "# Remove 'OI' column from df1\n",
    "df1.drop(columns=['OI'], inplace=True)\n",
    "\n",
    "# Convert 'Date' and 'Time' in df1 to datetime format and combine them\n",
    "df1['DateTime'] = pd.to_datetime(df1['Date'] + ' ' + df1['Time'])\n",
    "\n",
    "# Convert 'date' in df2 to datetime format\n",
    "df2['date'] = pd.to_datetime(df2['date']).dt.tz_localize(None)  # removing timezone info\n",
    "\n",
    "# Rename columns in df2 to match those in df1\n",
    "df2.rename(columns={'date':'DateTime', 'open':'Open', 'high':'High', 'low':'Low', 'close':'Close', 'volume':'Vol'}, inplace=True)\n",
    "\n",
    "# Merge the two dataframes on 'DateTime'\n",
    "df = pd.merge(df1, df2, on='DateTime', how='outer')\n",
    "\n",
    "# Write the merged dataframe to a new CSV file\n",
    "df.to_csv('nf_backtest_consolidated.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the data from the CSV file\n",
    "df = pd.read_csv('nf_backtest_consolidated.csv')\n",
    "\n",
    "# Convert 'DateTime' to datetime format\n",
    "df['DateTime'] = pd.to_datetime(df['DateTime'])\n",
    "\n",
    "# Extract date and time from 'DateTime'\n",
    "df['Date'] = df['DateTime'].dt.date\n",
    "df['Time'] = df['DateTime'].dt.time\n",
    "\n",
    "# Filter for rows where the time is 9:19\n",
    "df_919 = df[df['Time'] == pd.to_datetime('09:19').time()]\n",
    "\n",
    "# Create a new DataFrame containing just the date and 'Open' price at 9:19 for each date\n",
    "df_start_price = df_919[['Date', 'Open']].copy()\n",
    "df_start_price.columns = ['date', 'start_price']\n",
    "\n",
    "# Write the new DataFrame to a CSV file\n",
    "df_start_price.to_csv('nifty_919.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
